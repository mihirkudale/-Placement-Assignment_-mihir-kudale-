{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83d83bcc",
   "metadata": {},
   "source": [
    "### Question 2 - From Question 1, you would get a trained model which would classify the vegetables based on the classes. You need to convert the trained model to ONNX format and achieve faster inference\n",
    "Note -\n",
    "1. There is no set inference time, but try to achieve as low an inference time as\n",
    "possible\n",
    "2. Create a web app to interact with the model, where the user can upload the\n",
    "image and get predictions\n",
    "3. Try to reduce the model size considerably so that inference time can be faster\n",
    "4. Use modular Python scripts to train and infer the model\n",
    "5. Only Jupyter notebooks will not be allowed\n",
    "6. Write code comments whenever needed for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf03e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.onnx as onnx\n",
    "\n",
    "# Step 1: Train the Model (example code)\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "# Step 2: Convert the Model to ONNX Format\n",
    "# Load the trained model\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Example input tensor\n",
    "example_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Convert the model to ONNX format\n",
    "onnx_path = 'model.onnx'\n",
    "torch.onnx.export(model, example_input, onnx_path, export_params=True)\n",
    "\n",
    "print(f\"Model converted and saved as '{onnx_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb19a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the image and apply necessary transformations\n",
    "image_path = 'test_image.jpg'\n",
    "image = Image.open(image_path)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_data = preprocess(image)\n",
    "input_data = input_data.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnxruntime.InferenceSession('model.onnx')\n",
    "\n",
    "# Run the inference\n",
    "input_name = onnx_model.get_inputs()[0].name\n",
    "output_name = onnx_model.get_outputs()[0].name\n",
    "output = onnx_model.run([output_name], {input_name: input_data.numpy()})\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = np.argmax(output[0])\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d5b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    image = request.files['image']\n",
    "    image_path = 'uploaded_image.jpg'\n",
    "    image.save(image_path)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_data = preprocess(image)\n",
    "    input_data = input_data.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Load the ONNX model\n",
    "    onnx_model = onnxruntime.InferenceSession('model.onnx')\n",
    "\n",
    "    # Run the inference\n",
    "    input_name = onnx_model.get_inputs()[0].name\n",
    "    output_name = onnx_model.get_outputs()[0].name\n",
    "    output = onnx_model.run([output_name], {input_name: input_data.numpy()})\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = np.argmax(output[0])\n",
    "\n",
    "    return render_template('result.html', predicted_class=predicted_class)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
